# Import our dependencies
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,OneHotEncoder
import pandas as pd
import tensorflow as tf

# Import our input dataset
import pandas as pd
seldin_df = pd.read_csv("Resources/seldin_combined.csv")
seldin_df.tail(5)


# Drop categorical data not required
seldin_df = seldin_df.drop(columns=['id', 'gender'])
seldin_df.tail()


# Fill NaN with 6
seldin_df.superpopulation = seldin_df.superpopulation.fillna(5)
seldin_df.head()


# Replace superpopulation alpha label with numeric value
# Reference: https://www.geeksforgeeks.org/how-to-replace-values-in-column-based-on-condition-in-pandas/

seldin_df.loc[ seldin_df["superpopulation"] == "AFR", "superpopulation"] = 0
seldin_df.loc[ seldin_df["superpopulation"] == "AMR", "superpopulation"] = 1
seldin_df.loc[ seldin_df["superpopulation"] == "EAS", "superpopulation"] = 2
seldin_df.loc[ seldin_df["superpopulation"] == "EUR", "superpopulation"] = 3
seldin_df.loc[ seldin_df["superpopulation"] == "SAS", "superpopulation"] = 4
seldin_df.tail(50)


# Set superpopulation to data type 'integer'
# Reference: https://saturncloud.io/blog/how-to-replace-strings-with-numbers-in-python-pandas-dataframe/
seldin_df['superpopulation'] = seldin_df['superpopulation'].astype('int')


# Generate our categorical variable lists
categorical_var_list = seldin_df.dtypes[seldin_df.dtypes == "object"].index.tolist()
categorical_var_list


# Check the number of unique values in each column
seldin_df[categorical_var_list].nunique()


# Reference: https://stackoverflow.com/questions/63189787/typeerror-init-got-an-unexpected-keyword-argument-sparse   for issue with 'sparse'
# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html

# Create a OneHotEncoder instance
enc = OneHotEncoder (sparse_output=False)

# Fit and transform the OneHotEncoder using the categorical variable list
snp_encode_df = pd.DataFrame(enc.fit_transform(seldin_df[categorical_var_list]))

# Reference:https://stackoverflow.com/questions/58756515/onehotencoder-object-has-no-attribute-get-feature-names
# Add the encoded variable names to the dataframe
snp_encode_df.columns = enc.get_feature_names_out(categorical_var_list)
snp_encode_df.head()


# Merge one-hot encoded features and drop the originals
encoded_seldin_df = seldin_df.merge(snp_encode_df,left_index=True, right_index=True)
encoded_seldin_df  = encoded_seldin_df.drop(categorical_var_list, axis=1)
encoded_seldin_df.head()


# Split our preprocessed data into our features and target arrays

y = encoded_seldin_df["superpopulation"].values
X = encoded_seldin_df.drop(columns=['superpopulation'])


# Split the preprocessed data into a training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)


# Create a StandardScaler instances
scaler = StandardScaler()

# Fit the StandardScaler
X_scaler = scaler.fit(X_train)

# Scale the data
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


# Define the model - deep neural net
number_input_features = 635
hidden_nodes_layer1 =  8
hidden_nodes_layer2 = 5

nn = tf.keras.models.Sequential()

# First hidden layer
nn.add(
    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation="relu")
)
# Second hidden layer
nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation="relu"))

# Output layer
nn.add(tf.keras.layers.Dense(units=6, activation="softmax"))

# Check the structure of the model
nn.summary()


# Reference: https://stackoverflow.com/questions/63527580/tensorflow-with-keras-sparse-categorical-crossentropy
# Compile the model
nn.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])


# Train the model
fit_model = nn.fit(X_train_scaled,y_train,epochs=100)


# Evaluate the model using the test data
model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")


# Extract predictions
predictions = nn.predict(X)


# Get values
import numpy as np
classes = np.argmax(predictions, axis = 1)
predicted_suppop = classes.tolist()
original_suppop = seldin_df["superpopulation"].values.tolist()


output_df = pd.DataFrame({"superpopulation": original_suppop,
                         "guessed superpopulation": predicted_suppop})
output_df.tail(30)


# Convert back to names
suppops = ["AFR", "AMR", "EAS", "EUR", "SAS", ""]

for i in range(6):
    output_df.loc[output_df["superpopulation"] == i, "superpopulation"] = suppops[i]
    output_df.loc[output_df["guessed superpopulation"] == i, "guessed superpopulation"] = suppops[i]


output_df.tail(30)


# Export to csv
output_df.to_csv("Exhibits/NN_Seldin_Predictions.csv")
