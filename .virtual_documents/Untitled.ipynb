# Import our dependencies
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,OneHotEncoder
import pandas as pd
import tensorflow as tf

# Import our input dataset
import pandas as pd
kidd_df = pd.read_csv("Resources/kidd_combined.csv")
kidd_df.tail(5)


# Drop categorical data not required
kidd_df = kidd_df.drop(columns=['id', 'gender'])
kidd_df.tail()


# Fill NaN with 6
kidd_df.superpopulation = kidd_df.superpopulation.fillna(5)
kidd_df.head()


# Replace superpopulation alpha label with numeric value
# Reference: https://www.geeksforgeeks.org/how-to-replace-values-in-column-based-on-condition-in-pandas/

kidd_df.loc[ kidd_df["superpopulation"] == "AFR", "superpopulation"] = 0
kidd_df.loc[ kidd_df["superpopulation"] == "AMR", "superpopulation"] = 1
kidd_df.loc[ kidd_df["superpopulation"] == "EAS", "superpopulation"] = 2
kidd_df.loc[ kidd_df["superpopulation"] == "EUR", "superpopulation"] = 3
kidd_df.loc[ kidd_df["superpopulation"] == "SAS", "superpopulation"] = 4
kidd_df.tail(50)


# Set superpopulation to data type 'integer'
# Reference: https://saturncloud.io/blog/how-to-replace-strings-with-numbers-in-python-pandas-dataframe/
kidd_df['superpopulation'] = kidd_df['superpopulation'].astype('int')


# Generate our categorical variable lists
categorical_var_list = kidd_df.dtypes[kidd_df.dtypes == "object"].index.tolist()
categorical_var_list


# Check the number of unique values in each column
kidd_df[categorical_var_list].nunique()


# Reference: https://stackoverflow.com/questions/63189787/typeerror-init-got-an-unexpected-keyword-argument-sparse   for issue with 'sparse'
# Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html

# Create a OneHotEncoder instance
enc = OneHotEncoder (sparse_output=False)

# Fit and transform the OneHotEncoder using the categorical variable list
snp_encode_df = pd.DataFrame(enc.fit_transform(kidd_df[categorical_var_list]))

# Reference:https://stackoverflow.com/questions/58756515/onehotencoder-object-has-no-attribute-get-feature-names
# Add the encoded variable names to the dataframe
snp_encode_df.columns = enc.get_feature_names_out(categorical_var_list)
snp_encode_df.head()


# Merge one-hot encoded features and drop the originals
encoded_kidd_df = kidd_df.merge(snp_encode_df,left_index=True, right_index=True)
encoded_kidd_df  = encoded_kidd_df.drop(categorical_var_list, axis=1)
encoded_kidd_df.head()


# Split our preprocessed data into our features and target arrays

y = encoded_kidd_df["superpopulation"].values
X = encoded_kidd_df.drop(columns=['superpopulation'])


# Split the preprocessed data into a training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)


# Create a StandardScaler instances
scaler = StandardScaler()

# Fit the StandardScaler
X_scaler = scaler.fit(X_train)

# Scale the data
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


# Define the model - deep neural net
number_input_features = 275
hidden_nodes_layer1 =  8
hidden_nodes_layer2 = 5

nn = tf.keras.models.Sequential()

# First hidden layer
nn.add(
    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation="relu")
)
# Second hidden layer
nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation="relu"))

# Output layer
nn.add(tf.keras.layers.Dense(units=6, activation="softmax"))

# Check the structure of the model
nn.summary()


# Reference: https://stackoverflow.com/questions/63527580/tensorflow-with-keras-sparse-categorical-crossentropy
# Compile the model
nn.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])


# Train the model
fit_model = nn.fit(X_train_scaled,y_train,epochs=100)


# Evaluate the model using the test data
model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")



